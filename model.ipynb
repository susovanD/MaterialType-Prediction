{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we will create the model. \n",
    "First we will preprocess the data and then based on the data we try different modules and check which one works best.\n",
    "\n",
    "#### Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords #to get the english stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    le=WordNetLemmatizer()\n",
    "    import re\n",
    "except:\n",
    "    !pip install nltk\n",
    "    nltk.download('wordnet')\n",
    "    !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import excel file\n",
    "df=pd.read_csv(r\"Data/train_file.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us segregate the data into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df.drop('MaterialType',axis=1),df['MaterialType'],random_state=32,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data x shape :\",x_train.shape)\n",
    "print(\"Train data y shape :\",y_train.shape)\n",
    "print(\"Test data x shape :\",x_test.shape)\n",
    "print(\"Test data y shape :\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing the null data check we see that ~1250 records do not have subject. Similar check is done on the test data also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the blank data rows with space and then concatenate the Title and Subjects column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.Subjects.fillna(\" \",inplace=True)\n",
    "x_test.Subjects.fillna(\" \",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the columns title and subjects\n",
    "x_train['text']=x_train['Title']+\" \" + x_train['Subjects']\n",
    "x_test['text']=x_test['Title']+\" \" + x_test['Subjects']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that there are no null values for Subjects column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that the data is not actually balanced hence we can use weights on the data so that the minority class is also predicted accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the data is balanced\n",
    "y_test.value_counts()/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocess function preprocess the data and make it ready for ingestion by the model. Below preprocessing steps are followed:\n",
    "- Keep only alphabetical data. Numbers and punctuations are removed.\n",
    "- Convert the data to lower case.\n",
    "- Remove the frequently occuring stopwords.\n",
    "- Convert each word in the corpus into its lemma form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    cleaned_data=[]\n",
    "    for i in data:\n",
    "        text=re.sub('[^A-Za-z]',' ',i) #remove punctuations\n",
    "        text=text.lower() #convert to lower case\n",
    "        text=\" \".join([le.lemmatize(word) for word in text.split() if not word in stopwords.words('english')])#using stemmer to stem words and remove stopwords\n",
    "        cleaned_data.append(text)\n",
    "    return cleaned_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use preprocess function to do preprocessing of the data\n",
    "x_train['cleaned_text']=preprocess(x_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test['cleaned_text']=preprocess(x_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.cleaned_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the cleaned text data column into TFIDF matrix. Now the data is ready to be ingested by the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer(max_features=5000)\n",
    "x_train_tfidf=tfidf.fit_transform(x_train.cleaned_text)\n",
    "x_test_tfidf=tfidf.transform(x_test.cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to predict the materialType using the below models and then finalize on the most suitable one based on its performance . \n",
    "- Logistic Regression\n",
    "- Random Forest Classifier\n",
    "- Gradient Boosting Classifier\n",
    "- Naive Bayes\n",
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "models={'Logistic Regression':LogisticRegression(),\n",
    "        'Naive Bayes':MultinomialNB(),\n",
    "        'SVM':SVC(),\n",
    "        'Random Forest':RandomForestClassifier(),\n",
    "        'Gradient Boosting':GradientBoostingClassifier()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now check how the models perform without any hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,accuracy_score,f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "for nm,model in models.items():\n",
    "    model.fit(x_train_tfidf,y_train)\n",
    "    resp=model.predict(x_test_tfidf)\n",
    "    acc=accuracy_score(resp,y_test)\n",
    "    print(f\"{nm} - Accuracy : {acc*100}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us update the hyper parameters for each model and then use them to see if we can get better results.\n",
    "\n",
    "**Note** : Logistic Regression model did not converge by default and hence we will try to make it converge by increasing the max_iter parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_param={'Logistic Regression':{'max_iter':[100,500,1000],'solver':['saga'],'penalty':['l1'],'C':[0.9]},\n",
    "             'Naive Bayes':{},\n",
    "             'SVM':{'C': [1, 10], 'kernel': ['linear', 'rbf'],'class_weight':['balanced',None]},\n",
    "             'Random Forest':{'n_estimators':[100,200,400],'class_weight':['balanced','balanced_subsample']},\n",
    "             'Gradient Boosting':{'n_estimators':[100,200,400]}}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "for nm,model in models.items():\n",
    "    clf=GridSearchCV(model,hyper_param[nm],refit=True)\n",
    "    clf.fit(x_train_tfidf,y_train)\n",
    "    resp=clf.predict(x_test_tfidf)\n",
    "    acc=accuracy_score(resp,y_test)\n",
    "    print(f\"Model Used : {nm}\\nModel Parameters : {clf.best_estimator_}\\nModel Accuracy : {acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Even after updating the max_iter convergence issue did not go away.\n",
    "- GradientBoosting Classifier also faced issue with model fitting. **(Feel free to update me resolve this error.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we can see that SVM and Randomforest deos the best job in identifying. Let us check their accuracy and precission score also\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score,f1_score,confusion_matrix,classification_report\n",
    "for nm,clf in models.items():\n",
    "    if nm=='SVM' or nm=='Random Forest':\n",
    "        clf=GridSearchCV(clf,hyper_param[nm],refit=True)\n",
    "        clf.fit(x_train_tfidf,y_train)\n",
    "        ypred=clf.predict(x_test_tfidf)\n",
    "        print(f\"\\n\\nModel {nm} \\nClassification Report : \\n\",classification_report(y_test,ypred))\n",
    "#print(\"Recall Score : \",recall_score(y_test,ypred,average='macro'))\n",
    "#print(\"Precission Score : \",precision_score(y_test,ypred,average='macro'))\n",
    "#print(\"Confusionn Matrix\",confusion_matrix(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### From here we see that both are having similar accuracy. Random forest seems to work a bit better.\n",
    "###### Future Improvement:\n",
    "- **VideoCass** and **VideoDisk** seems to have lesser recall than the major classes like Book,Sound, Video.\n",
    "- This can be further improved by doing the below:\n",
    "    - Use data sampling technique to increase the data points for classes where minimal data is present.\n",
    "    - Merge all these different categories into larger groups containing **Book**, **Sound** and **Video**. (Miscelleneous may be removed/ignored since the count is less than even 1%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
